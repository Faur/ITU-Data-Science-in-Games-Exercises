{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural networks 101\n",
    "\n",
    "\n",
    "Convolutional neural networks (or ConvNets) are a very succesfull type of neural networks, and are an integral part of reigniting the interest in neural networks.\n",
    "They are abel to extract structural relations in the data such as spatial in images or temporal in time series.\n",
    "\n",
    "Jason Yosinski and colleague developed a [toolbox for visualizing convolutional networks](http://yosinski.com/deepvis).\n",
    "Unfortunately this toolbox is for *Caffe*, so we can't use it here, but they made a [VERY INSTRUCTIVE VIDEO](https://www.youtube.com/watch?v=AgkfIQ4IGaM) that does a great job of conveying the intuitions.\n",
    "\n",
    "In this lab you will learn what *convolutional layers* are and how they work, as well as important related concepts such as *padding*, *stride*, and *pooling*.\n",
    "\n",
    "\n",
    "\n",
    "#### External resources:\n",
    "For an indept tutorial please see [stanford cs231n](http://cs231n.github.io/convolutional-networks/) or to read more see [Michael Nielsen](http://neuralnetworksanddeeplearning.com/chap6.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are convolutional networks?\n",
    "\n",
    "ConvNets are in may respects very similar to the dense feedforward networks we saw previously:\n",
    " * The network is still organized into layers\n",
    " * Each layer is parameterized by weights and biases\n",
    " * Each layer has an element-wise non-linear transformation (activation function)\n",
    " * There are no cycles in the connections (more on this in later labs)\n",
    "\n",
    "*So what is the difference?*\n",
    "The networks we saw previously are called *dense* because each unit receives input from all the units in the previous layer.\n",
    "This is not the case for ConvNets.\n",
    "In ConvNets each unit is only connected to a small subset of the input units.\n",
    "This is called the *receptive field* of the unit.\n",
    "\n",
    "#### Let us look at a quick example.\n",
    "Let us define a `3x3` window with the kernel weights (indicated by red in the bottom right).\n",
    "We apply the window by performning elementwise multiplication, and then summing the results, as shown in this animation:\n",
    "\n",
    "![](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)\n",
    "[GIF courtesy of [Stanford](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)]\n",
    "\n",
    "After having convolved the image we perform an elementwise non-linear transformation on the *convolved features*.\n",
    "In this example the input is a 2D *feature map* with depth 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strides, padding, and pooling\n",
    "\n",
    "Two important concepts for ConvNets are *strides* and *padding*.\n",
    "### Padding\n",
    "describes what we do at the edges of the feature map.\n",
    "If we don't use padding the feature map will get smaller every time, as we can see above. \n",
    "If we do use padding we can maintain the same resolution. \n",
    "In deep learning we generally just pad with zeros.\n",
    "In the example below in the '_Padding, no strides_' GIF we maintain the size by padding with one row/column of zeros on all sides.\n",
    "\n",
    "\n",
    "### Strides\n",
    "describe how far the window is moved each time. Strides can be used to reduce the size of the feature map, and the number of computations that needs to be performed.\n",
    "\n",
    "    Strides and pooling (exerpted from [here](https://github.com/vdumoulin/conv_arithmetic#convolution-animations)) are shown in the table below.\n",
    "Notice how the output (green) changes shape.\n",
    "\n",
    "| ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif) | ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides.gif) | ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_strides.gif) | ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides.gif) |\n",
    "|--------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| No padding, no strides                                                                     | Padding, no strides                                                                          | No padding, stride of 2                                                                 | Padding, stride of 2                                                                 |\n",
    "\n",
    "\n",
    "### Pooling\n",
    "is another method for reducing the spatial resolution. Similar to convolutional layers it works by sliding a window accross the feature map. Unlike the convolutional layers there are no learnable parameters, and the pooling layers perform the same simple operation every time. The most common types of pooling are:\n",
    " * *Max pooling* where the output of the pooling operation is the highest value in the window, and\n",
    " * *Mean pooling* which outputs the mean of the elements in the window.\n",
    " \n",
    "![Max pooling image](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Max_pooling.png/471px-Max_pooling.png)\n",
    "[Image courtesy of [Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependancies and supporting functions by running the code block below.\n",
    "from __future__ import absolute_import, division, print_function \n",
    "\n",
    "# import time\n",
    "# import sys, os\n",
    "\n",
    "%matplotlib inline\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "# from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Download and load data\n",
    "data_set = keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train_),(x_test, y_test_) = data_set.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize data to [0, 1] interval\n",
    "\n",
    "y_train = OneHotEncoder(categories='auto', sparse=False).fit_transform(y_train_)\n",
    "y_test = OneHotEncoder(categories='auto', sparse=False).fit_transform(y_test_)\n",
    "\n",
    "## Print dataset statistics and visualize\n",
    "print(\"\"\"Information on dataset\n",
    "----------------------\"\"\")\n",
    "print(\"Training data shape:\\t\", x_train.shape, y_train.shape)\n",
    "print(\"Test data shape\\t\\t\",     x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a few MNIST examples\n",
    "img_to_show = 5\n",
    "idx = 0\n",
    "canvas = np.zeros((32*img_to_show, img_to_show*32, 3))\n",
    "print('\\nLabels')\n",
    "for i in range(img_to_show):\n",
    "    for j in range(img_to_show):\n",
    "        canvas[i*32:(i+1)*32, j*32:(j+1)*32] = x_train[idx] #mnist_data.train.images[idx].reshape((28, 28))\n",
    "        print(y_train_[idx], end=', ')\n",
    "        idx += 1\n",
    "    print()\n",
    "\n",
    "print('\\nInput data')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(canvas)\n",
    "plt.title('Example data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Getting use to Convolutional Networks\n",
    "\n",
    "In this first part you shuold experiment a bit, and get used to working with convolutional networks.\n",
    "Later you will get to try and work  you will apply what you have done.\n",
    "\n",
    "You task is:\n",
    "\n",
    "1) Create a convolutional neural network, using both `Conv2D`, `MaxPooling2D` layers, with the following shapes:\n",
    "\n",
    "    (None, 28, 28, 1) [input]\n",
    "    (None, 14, 14, 16)\n",
    "    (None, 6, 6, 32)\n",
    "    (None, 4, 4, 64)\n",
    "    (None, 2, 2, 64)\n",
    "    (None, 1, 1, 128)\n",
    "\n",
    "2) How many trainable parameters parameters does this network have?\n",
    " * `keras.model.summary` is an easy way to see the number of parameters.\n",
    "\n",
    "\n",
    "3) Create a dense network with (roughly) the same number of parameters, and compare the summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_model = None ## YOUR CODE HERE!\n",
    "\n",
    "conv_model = keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer((32, 32, 3)),\n",
    "    \n",
    "    keras.layers.Conv2D(16, (3,3), strides=(2,2), padding='same'),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(32, (3,3), strides=(2,2), padding='valid'),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='valid'),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid'),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(128, (2,2), strides=(1,1), padding='valid'),\n",
    "    keras.layers.Activation('relu'),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = None ## YOUR CODE HERE!\n",
    "\n",
    "dense_model = keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer((32, 32, 3)),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    keras.layers.Dense(19),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: \n",
    "\n",
    "Now we want to compare the performance of dense and convolutional networks, and conduct some experiments.\n",
    "\n",
    "Your task\n",
    "\n",
    "1. Go back to Task 1, and update the networks such that they work (e.g. have non-linearities, and a soft-max output layer)\n",
    "1. Finish the code below, and compare the performance of the convolutional and dense network.\n",
    "1. For the remainder of the time try setting up hypothesies, and test them\n",
    " * How large does the dense network need to be in order to get similar performance as the convolotional?\n",
    " * When does an un-regularized convolutional network begin to overfit the data?\n",
    " * How does image preprocessing affect performance (especially in the reduced dataset case).\n",
    "\n",
    "___\n",
    "**Tip:** It might make sense to experiment with a reduced data set.\n",
    "You can remove observations, all occurances of some classes, or use a smaller data set (e.g. fashion MNIST).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copied from Lab 7\n",
    "\n",
    "try:\n",
    "    experiments\n",
    "except NameError:\n",
    "    experiments = []\n",
    "\n",
    "    \n",
    "def visualize_info(experiment):\n",
    "    name, _, info = experiment\n",
    "    print('Params:')\n",
    "    for key in info.params:\n",
    "        print('{:20}'.format(key), info.params[key])\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = plt.subplot(\"211\")\n",
    "    ax.set_title('Accuracy: '+ name)\n",
    "    plt.plot(info.history['val_acc'], label='val_acc')\n",
    "    plt.plot(info.history['acc'], label='train_acc')\n",
    "    plt.legend()\n",
    "\n",
    "    ax = plt.subplot(\"212\")\n",
    "    ax.set_title('Loss: ' + name)\n",
    "    plt.plot(info.history['val_loss'], label='val_loss')\n",
    "    plt.plot(info.history['loss'], label='loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_experiments(experiments):\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    for experiment in experiments:\n",
    "        exp_name, _, info = experiment\n",
    " \n",
    "        ax = plt.subplot(\"211\")\n",
    "        ax.set_title('Validation Accuracy')\n",
    "        plt.plot(info.history['val_acc'], label=exp_name)\n",
    "        plt.legend()\n",
    "\n",
    "        ax = plt.subplot(\"212\")\n",
    "        ax.set_title('Validation Loss')\n",
    "        plt.plot(info.history['val_loss'], label=exp_name)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def keep_best(experiments, n):\n",
    "    \"\"\" Return the n best experiments.\"\"\"\n",
    "    if len(experiments) < n:\n",
    "        return experiments\n",
    "    \n",
    "    exp_sorted = sorted(experiments, key=lambda x: np.max(x[2].history['val_acc']), reverse=True)\n",
    "    return exp_sorted[:n]\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train(model, loss, optimizer, num_epochs, exp_name=None, use_tensorboard=False):    \n",
    "    exp_name = exp_name or 'log_{:.0f}'.format(time.time()*100)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    batch_size = 256\n",
    "\n",
    "    if use_tensorboard:\n",
    "        tensorboard = TensorBoard(log_dir='logdir/'+exp_name)\n",
    "        fit_info = model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.1, callbacks=[tensorboard])\n",
    "    else:\n",
    "        fit_info = model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.1)\n",
    "    return exp_name, model, fit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_function = None\n",
    "optimizer = None\n",
    "\n",
    "## YOUR CODE HERE!\n",
    "\n",
    "loss_function = tf.keras.backend.categorical_crossentropy\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "num_epochs = 25\n",
    "print('\\nBegin Training')\n",
    "exp_name = 'conv_network'\n",
    "experiment = train(conv_model, loss_function, optimizer, num_epochs, exp_name=exp_name)\n",
    "experiments.append(experiment)\n",
    "\n",
    "exp_name = 'dense_network'\n",
    "experiment = train(dense_model, loss_function, optimizer, num_epochs, exp_name=exp_name)\n",
    "experiments.append(experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_experiments(experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear Classifiers with Keras and TensorFlow\n",
    "\n",
    "TensorFlow is an open source software library for numerical computation that can be used for many things, but is mostly know for its use for deep and machine learning.\n",
    "Since its release in 2015 it has quickly become one of the most popular and most actively developed libraries for deep learning.\n",
    "TensorFlow represents computations as graphs, which enables simple parallelization, and automatic differentiation.\n",
    "\n",
    "Pure TensorFlow is very verbose, and it is therefore a good idea to use a high-level API.\n",
    "Doing so simplifies and speeds-up development, reduces the risk of bugs, and generally reduces headache.\n",
    "The officially supported high-level API is **[Keras](https://keras.io/)**, and will be the focus of this lab.\n",
    "\n",
    "\n",
    "### External resources\n",
    "If you want a deeper dive the following are good places to start:\n",
    "\n",
    "* [Official getting started material](https://www.tensorflow.org/get_started/) - collection of good tutorials from beginer to very advanced.\n",
    "* [API documentation](https://www.tensorflow.org/api_docs/python/) - Most of the documentation for TF is written into the code, so the best way to figure out how somethings works is often to look it up in the API, and then look at the implementation. The [API guides](https://www.tensorflow.org/api_guides/python/array_ops) can also be very useful sometimes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Crash course\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependancies and supporting functions by running the code block below.\n",
    "from __future__ import absolute_import, division, print_function \n",
    "\n",
    "import time\n",
    "import sys, os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "For this exercise we will use the [fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset.\n",
    "Like the classical MNIST data set it consists of images `28x28` grayscale images of of 10 different classes, and the objective is to correctly classify as many of them as possible.\n",
    "Fashion-MNIST is however more challenging (though still a toy-dataset), making it more interesting to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load data\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "valid_size = 5000\n",
    "train_size = None  # Use this to limit the size of the training set (fast experiments)\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize data to [0, 1] interval\n",
    "\n",
    "# x_valid = x_train[:valid_size]\n",
    "# y_valid = y_train[:valid_size]\n",
    "# x_train = x_train[valid_size:]\n",
    "# y_train = y_train[valid_size:]\n",
    "\n",
    "## Print dataset statistics and visualize\n",
    "print(\"\"\"Information on dataset\n",
    "----------------------\"\"\")\n",
    "print(\"Training data shape:\\t\", x_train.shape, y_train.shape)\n",
    "print(\"Validation data shape\\t\", x_valid.shape, y_valid.shape)\n",
    "print(\"Test data shape\\t\\t\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion-MNIST consists of images of 10 different types of clothing.\n",
    "The labels are:\n",
    "\n",
    "| Label:       | 0           | 1       | 2        | 3     |    4 | 5     | 6      | 7      | 8   |   9 |\n",
    "| -| -| -| -| -| -| -| -| -| -| -|\n",
    "| **Description:** | T-shirt/top | Trouser | Pullover | Dress | Coat | Sandal | Shirt | Sneaker | Bag | Ankle boot |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a few MNIST examples\n",
    "img_to_show = 5\n",
    "idx = 0\n",
    "canvas = np.zeros((28*img_to_show, img_to_show*28))\n",
    "print('\\nLabels')\n",
    "for i in range(img_to_show):\n",
    "    for j in range(img_to_show):\n",
    "        canvas[i*28:(i+1)*28, j*28:(j+1)*28] = x_train[idx]#mnist_data.train.images[idx].reshape((28, 28))\n",
    "        print(y_train[idx], end=', ')\n",
    "        idx += 1\n",
    "    print()\n",
    "\n",
    "print('\\nInput data')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(canvas, cmap='gray')\n",
    "plt.title('MNIST handwritten digits')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to learn\n",
    "* An network architecture\n",
    " * # units\n",
    " * non-linearity\n",
    " * Number and type of layers\n",
    "* Training parameters\n",
    " * Learning algorithm + parameters\n",
    "* Regularization\n",
    " * Early stopping \n",
    " * drop out\n",
    " * weight decay\n",
    " * batch norm\n",
    "* visualizing the loss\n",
    "* TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available [loss functions](https://keras.io/losses/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss='categorical_crossentropy', optimizer='adam', exp_name=None):\n",
    "    exp_name = exp_name or '{:.0f}'.format(time.time()*10)\n",
    "    print(exp_name)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir='logdir/log_{}'.format(time.time()))\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=5)#, callbacks=[tensorboard]) #, validation_split\n",
    "    model.evaluate(x_test, y_test)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

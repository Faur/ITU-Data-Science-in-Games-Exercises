{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 Classification and Regression\n",
    "\n",
    "This week's exercise will be a bit shorter. The objective is to implement the core of the k-nn algorithm (most of the pre-processing and evaluation is given), followed by a Q&A moment\n",
    "\n",
    "Schedule:\n",
    "* Classify data using k-means\n",
    "* Use a confusion matrix to evluate models\n",
    "* Q&A on the last lectures\n",
    "\n",
    "## Reminders\n",
    "* [GitHub repo](https://github.com/Faur/ITU-Data-Science-in-Games-Exercises)\n",
    "* **Shut down notebooks** when you are done. Otherwise the server will run out of resources, and we will be forced to restart the them.\n",
    "* Server storage is volatile! I.e. you must **save everything locally** that you don't want to loose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes matplotlib plots work better with Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the necessary libraries. \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check that data and data path is present\n",
    "basedir = \"../\"\n",
    "file = \"fifa.csv\"\n",
    "assert os.path.isdir(f\"{basedir}data\") and os.path.exists(f\"{basedir}data/{file}\"), 'Data not found. Make sure to have the most recent version!'\n",
    "\n",
    "data = pd.read_csv(f'{basedir}/data/fifa.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, height=5,hue=\"Position\").map(plt.scatter,\"SprintSpeed\",\"Agility\").add_legend()\n",
    "sns.FacetGrid(data, height=5,hue=\"Position\", col='Preferred Foot').map(plt.scatter,\"ShotPower\",\"Strength\").add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem\n",
    "\n",
    "0. pick a value for K (number of clusters) and N (number of neighbors)\n",
    "1. split the data in train and validation set\n",
    "2. normalize fields (in our case the data are already normalized)\n",
    "3. foreach `datapoint` in `validation set`:\n",
    "  1. find the N nearest neighbors\n",
    "  2. set as label of `datapoint` the label that appears most between its neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Crossing','Finishing','HeadingAccuracy','ShortPassing','Volleys','Dribbling','Curve','FKAccuracy','LongPassing','BallControl','Acceleration','SprintSpeed','Agility','Reactions','Balance','ShotPower','Jumping','Stamina','Strength','LongShots','Aggression','Interceptions','Positioning','Vision','Penalties','Composure','Marking','StandingTackle','SlidingTackle','GKDiving','GKHandling','GKKicking','GKPositioning','GKReflexes']\n",
    "class_col = 'Position'\n",
    "\n",
    "# cleaning: remove all the lines that contain a NaN in one of the feature columns\n",
    "data = data.dropna(subset=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: define K and N\n",
    "K = 5\n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: split\n",
    "\n",
    "# random split. It's always a good idea (maybe the dataset is sorted, and so on).\n",
    "# df.sample has a parameter random_state that allows you to always get the same split (useful for testing). Check docs\n",
    "train_set = data.sample(frac=0.995)\n",
    "valid_set = data.drop(train_set.index)\n",
    "\n",
    "valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "# 3: classify\n",
    "nearest_neighbors = lambda x: (train_set[features].sub(x[features])\n",
    "                               .pow(2).sum(1).pow(0.5)\n",
    "                               .nsmallest(N)  # \n",
    "                               )\n",
    "\n",
    "classify = lambda x: (train_set.iloc[nearest_neighbors(x)]\n",
    "                      [class_col]\n",
    "                      .mode()[0])\n",
    "\n",
    "classified_set = valid_set\n",
    "# classified_set.reset_index()\n",
    "# classified_set\n",
    "classified_set['Calculated Position'] = valid_set.apply(classify, axis=1)\n",
    "classified_set[['Position', 'Calculated Position']]\n",
    "# classified_set.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "\n",
    "data['Goalkeeper'] = data['Position'] == 'GK'\n",
    "data\n",
    "\n",
    "class_col = 'Goalkeeper'\n",
    "\n",
    "train_set = data.sample(frac=0.99)\n",
    "valid_set = data.drop(train_set.index)\n",
    "\n",
    "classified_set = valid_set\n",
    "classified_set['Calculated Goalkeeper'] = valid_set.apply(classify, axis=1)\n",
    "classified_set[['Goalkeeper', 'Calculated Goalkeeper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(classified_set[classified_set['Goalkeeper'] == classified_set['Calculated Goalkeeper']]) / len(classified_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification evaluation\n",
    "\n",
    "1. generate confusion matrix\n",
    "2. evaluate the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig\n",
    "\n",
    "labels = data[class_col].unique()\n",
    "classified_set[[class_col, f'Calculated {class_col}']]\n",
    "cm = confusion_matrix(classified_set[class_col], classified_set[f'Calculated {class_col}'], labels=labels)\n",
    "\n",
    "print_confusion_matrix(\n",
    "    cm,\n",
    "    labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "err_rate = (fp + fn) / (tn + fp + fn + tp)\n",
    "sensitiv = (tp) / (fp + tp)\n",
    "specific = (tn) / (tn + fn)\n",
    "\n",
    "print(cm.ravel())\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Error rate: {err_rate}')\n",
    "print(f'Sensitivity: {sensitiv}')\n",
    "print(f'Specificity: {specific}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
